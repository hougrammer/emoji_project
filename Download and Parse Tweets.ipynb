{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from http://www.mikaelbrunila.fi/2017/03/27/scraping-extracting-mapping-geodata-twitter/\n",
    "# https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import re\n",
    "import json\n",
    "import fileinput\n",
    "import collections\n",
    "import json_lines\n",
    "import csv\n",
    "\n",
    "consumer_key = '93WP2pKvICGqCvrdA6FWMbFLB'\n",
    "consumer_secret = 'LWcPKp3oqEmYTTbVaNpRD5tgqLl2KAfe2bNGsBk5xwTjxLxqHH'\n",
    "access_token = '3080541417-QQ15kHSfkZYBWWSqLHwKwfqB3INeYgxpY3P9IbO'\n",
    "access_secret = '2nuMVxvX8TzMyl1xHkUvElNy6BqWjqdoolTvLLxwoXHi1'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "place_id = places[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "en\n",
      "I don't know where I'd be without my caregivers, my mom and dad, and also family, friends, people who are just ther… https://t.co/SvBIKHV5pl | Manhattan\n",
      "en\n",
      "Don’t force a relationship just have fun Nd boolit💯 | Forestville\n",
      "und\n",
      "#GoJags | Tampa\n",
      "en\n",
      "Let's go march down the field again | Athens\n",
      "tr\n",
      "Yağmur, soğukla birlikte olmadığı zamanlarda harika ama, birlikte hiç çekilmiyorlar. | United States\n",
      "en\n",
      "This is so Kyshawn lol https://t.co/F85FHA7D8g | Fort Lee\n",
      "en\n",
      "@TimDabney74 @TheCardConnect So did Griff | Iowa\n",
      "es\n",
      "Altas temperaturas en las lomas del norte a las 1¨30PM desde los 87 a los 90ºF en algunas localidades. https://t.co/F8BZJNm12M | Puerto Rico\n"
=======
      "❤🐶woww wowww wowwww\n",
      "🐶❤ this diving dog can https://t.co/40MG6yJ1po | Ballenger Creek\n",
      "Go check out my mans youtube channel for the reviews on shoe apparel and more‼️‼️‼️ https://t.co/FZa0rPDbKO | North Carolina\n",
      "https://t.co/uMVOMyncfT | Chicago\n",
      "https://t.co/IBKoxW14qk | West Virginia\n",
      "I See You Tank... | New Jersey\n",
      "This O line is awful | Georgia\n",
      "@FatyCepeda We love a supportive queen https://t.co/piK8cgNfEH | Dallas\n",
      "@AndyHemmings66 Blankets are hope's nirvana https://t.co/IiIpBfmAmL | West Melbourne\n",
      "But anyway I love my man with all my heart. So 10/10 I’m keeping him ❤️ | Fontana\n"
>>>>>>> 2d21db5dbcf70864874255d45dd8b57b3bcbb1c2
     ]
    }
   ],
   "source": [
    "tweets = api.search(q=\"place:%s\" % place_id)\n",
    "for tweet in tweets:\n",
    "    print(tweet.metadata['iso_language_code'])\n",
    "    print(tweet.text + \" | \" + tweet.place.name if tweet.place else \"Undefined place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barbieri_clean_up(tweet,original = True):\n",
    "    #casefold() lowercases all words. Replace corrects for emojis that are not separated by space to words. \n",
    "    if original: \n",
    "        raw = tweet.text.casefold().encode(encoding = 'unicode-escape').decode().replace('\\\\U',' \\\\U').split() \n",
    "    else:\n",
    "        raw = tweet.casefold().encode(encoding = 'unicode-escape').decode().replace('\\\\U',' \\\\U').split() \n",
    "    #remove all hyperlinks\n",
    "    new_raw = []\n",
    "    for item in raw:\n",
    "        if item.find('http') == -1:\n",
    "            if item.find('#') == -1:\n",
    "                if item.find('@') == -1:\n",
    "                    new_raw.append(item)\n",
    "    return ' '.join(new_raw)\n",
    "\n",
    "def emoji_count(clean_tweet):\n",
    "    i = 0\n",
    "    for item in clean_tweet:\n",
    "        if item.find('\\\\U') > -1:\n",
    "            i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "I don't know where I'd be without my caregivers, my mom and dad, and also family, friends, people who are just ther… https://t.co/SvBIKHV5pl\n",
      "Don’t force a relationship just have fun Nd boolit💯\n",
      "#GoJags\n",
      "Let's go march down the field again\n",
      "Yağmur, soğukla birlikte olmadığı zamanlarda harika ama, birlikte hiç çekilmiyorlar.\n",
      "This is so Kyshawn lol https://t.co/F85FHA7D8g\n",
      "@TimDabney74 @TheCardConnect So did Griff\n",
      "Altas temperaturas en las lomas del norte a las 1¨30PM desde los 87 a los 90ºF en algunas localidades. https://t.co/F8BZJNm12M\n",
      "\n",
      "i don't know where i'd be without my caregivers, my mom and dad, and also family, friends, people who are just ther\\u2026\n",
      "\n",
      "0\n",
      "\n",
      "don\\u2019t force a relationship just have fun nd boolit \\U0001f4af\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "let's go march down the field again\n",
      "\n",
      "0\n",
      "\n",
      "ya\\u011fmur, so\\u011fukla birlikte olmad\\u0131\\u011f\\u0131 zamanlarda harika ama, birlikte hi\\xe7 \\xe7ekilmiyorlar.\n",
      "\n",
      "0\n",
      "\n",
      "this is so kyshawn lol\n",
      "\n",
      "0\n",
      "\n",
      "so did griff\n",
      "\n",
      "0\n",
      "\n",
      "altas temperaturas en las lomas del norte a las 1\\xa830pm desde los 87 a los 90\\xbaf en algunas localidades.\n",
=======
      "❤🐶woww wowww wowwww\n",
      "🐶❤ this diving dog can https://t.co/40MG6yJ1po\n",
      "Go check out my mans youtube channel for the reviews on shoe apparel and more‼️‼️‼️ https://t.co/FZa0rPDbKO\n",
      "https://t.co/uMVOMyncfT\n",
      "https://t.co/IBKoxW14qk\n",
      "I See You Tank...\n",
      "This O line is awful\n",
      "@FatyCepeda We love a supportive queen https://t.co/piK8cgNfEH\n",
      "@AndyHemmings66 Blankets are hope's nirvana https://t.co/IiIpBfmAmL\n",
      "But anyway I love my man with all my heart. So 10/10 I’m keeping him ❤️\n",
      "\n",
      "['\\\\u2764', '\\\\U0001f436woww', 'wowww', 'wowwww\\\\n', '\\\\U0001f436\\\\u2764', 'this', 'diving', 'dog', 'can']\n",
      "\n",
      "2\n",
      "\n",
      "['go', 'check', 'out', 'my', 'mans', 'youtube', 'channel', 'for', 'the', 'reviews', 'on', 'shoe', 'apparel', 'and', 'more\\\\u203c\\\\ufe0f\\\\u203c\\\\ufe0f\\\\u203c\\\\ufe0f']\n",
      "\n",
      "0\n",
      "\n",
      "[]\n",
      "\n",
      "0\n",
      "\n",
      "[]\n",
      "\n",
      "0\n",
      "\n",
      "['i', 'see', 'you', 'tank...']\n",
      "\n",
      "0\n",
      "\n",
      "['this', 'o', 'line', 'is', 'awful']\n",
      "\n",
      "0\n",
      "\n",
      "['@fatycepeda', 'we', 'love', 'a', 'supportive', 'queen']\n",
      "\n",
      "0\n",
      "\n",
      "['@andyhemmings66', 'blankets', 'are', \"hope's\", 'nirvana']\n",
      "\n",
      "0\n",
      "\n",
      "['but', 'anyway', 'i', 'love', 'my', 'man', 'with', 'all', 'my', 'heart.', 'so', '10/10', 'i\\\\u2019m', 'keeping', 'him', '\\\\u2764\\\\ufe0f']\n",
>>>>>>> 2d21db5dbcf70864874255d45dd8b57b3bcbb1c2
      "\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "[print(tweet.text) for tweet in tweets]\n",
    "print()\n",
    "for tweet in tweets:\n",
    "    clean_tweet = barbieri_clean_up(tweet)\n",
    "    print(clean_tweet)\n",
    "    print()\n",
    "    print(emoji_count(clean_tweet))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/tweet_id_files/twitter-events-2012-2016/2012-euro2012.jsonl\n",
      "./data/tweet_id_files/twitter-events-2012-2016/2012-mexican-election.jsonl\n",
      "./data/tweet_id_files/twitter-events-2012-2016/2012-superbowl.jsonl\n",
      "./data/tweet_id_files/twitter-events-2012-2016/2012-sxsw.jsonl\n",
      "😁  1619\n",
      "😜  1457\n",
      "😍  1126\n",
      "😃  1082\n",
      "😂   856\n",
      "😊   817\n",
      "😄   811\n",
      "😉   638\n",
      "😳   516\n",
      "😒   485\n",
      "😔   457\n",
      "😝   439\n",
      "😘   396\n",
      "😭   388\n",
      "😏   378\n",
      "😡   375\n",
      "😱   373\n",
      "🙏   280\n",
      "😢   255\n",
      "😞   192\n",
      "🙆   184\n",
      "🙌   145\n",
      "😖   131\n",
      "😠   126\n",
      "😲   111\n",
      "😰   102\n",
      "😌   101\n",
      "😥    97\n",
      "😓    96\n",
      "😣    62\n",
      "😪    60\n",
      "😨    52\n",
      "😚    47\n",
      "😷    38\n",
      "🙅    15\n",
      "🙇     4\n",
      "🙈     3\n",
      "😎     2\n",
      "🙉     1\n",
      "🙀     1\n"
     ]
    }
   ],
   "source": [
    "folder = './data/tweet_id_files/twitter-events-2012-2016/'\n",
    "paths = [folder + '2012-euro2012.jsonl',folder + '2012-mexican-election.jsonl',folder + '2012-superbowl.jsonl',\n",
    "         folder + '2012-sxsw.jsonl']\n",
    "\n",
    "regex = re.compile(r'\\d+(.*?)(?:\\u263a|\\U0001f645)')\n",
    "counts = collections.Counter()\n",
    "filtered_tweets_text = []\n",
    "with open(\"output.csv\", \"w\") as csv:\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        f = open(path,'rb')\n",
    "        for line in json_lines.reader(f):\n",
    "            tweet = line\n",
    "            if 'metadata' in tweet:\n",
    "                l = tweet.metadata['iso_language_code']\n",
    "            else:\n",
    "                l = tweet['lang']\n",
    "            if l == 'en':\n",
    "                if 'full_text' in tweet:\n",
    "                    text = tweet['full_text']\n",
    "                else:\n",
    "                    text = tweet['text']\n",
    "                e = re.findall(u'[\\U0001f600-\\U0001f650]', text)\n",
    "                if len(e)>0:\n",
    "                    clean = barbieri_clean_up(text,original = False)\n",
    "                    filtered_tweets_text += [clean]\n",
    "                    row = clean + '\\n'\n",
    "                    csv.write(row)\n",
    "                for char in e:\n",
    "                    counts[char] += 1   \n",
    "        f.close()\n",
    "\n",
    "for char, count in counts.most_common():\n",
    "    print(\"%s %5i\" % (char, count))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6-0 and where the men of goals. \\\\U0001f60d',\n",
       " \"quite looking forward to come on england \\\\U0001f60d big roy's army\",\n",
       " '\\\\U0001f49c \\\\U0001f49c \\\\U0001f49c \\\\U0001f49c \\\\U0001f60d and the whole netherlands team',\n",
       " 'this day next week \\\\u26bd \\\\U0001f340 \\\\U0001f49a \\\\U0001f60a',\n",
       " 'rt this day next week \\\\u26bd \\\\U0001f340 \\\\U0001f49a \\\\U0001f60a']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tweets_text[0:5]"
   ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 2d21db5dbcf70864874255d45dd8b57b3bcbb1c2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
