{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidhou8791/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from faker import Faker\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "# from utilities import show_graph\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "fake.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY',\n",
    "           ]\n",
    "\n",
    "# change this if you want it to work with only a single language\n",
    "LOCALES = babel.localedata.locale_identifiers()\n",
    "LOCALES = [lang for lang in LOCALES if 'en' in str(lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date():\n",
    "    \"\"\"\n",
    "        Creates some fake dates \n",
    "        :returns: tuple containing \n",
    "                  1. human formatted string\n",
    "                  2. machine formatted string\n",
    "                  3. date object.\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    # wrapping this in a try catch because\n",
    "    # the locale 'vo' and format 'full' will fail\n",
    "    try:\n",
    "        human = format_date(dt,\n",
    "                            format=random.choice(FORMATS),\n",
    "                            locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.randint(0,3) # 1/2 chance of case change\n",
    "        if case_change == 1:\n",
    "            human = human.upper()\n",
    "        elif case_change == 2:\n",
    "            human = human.lower()\n",
    "\n",
    "        machine = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human, machine #, dt\n",
    "\n",
    "data = [create_date() for _ in range(50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7 07 13', '2013-07-07'),\n",
       " ('30 JULY 1977', '1977-07-30'),\n",
       " ('Tuesday, 14 September 1971', '1971-09-14'),\n",
       " ('18 09 88', '1988-09-18'),\n",
       " ('31, Aug 1986', '1986-08-31')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x, y in data]\n",
    "y = [y for x, y in data]\n",
    "\n",
    "u_characters = set(' '.join(x))\n",
    "char2numX = dict(zip(u_characters, range(len(u_characters))))\n",
    "\n",
    "u_characters = set(' '.join(y))\n",
    "char2numY = dict(zip(u_characters, range(len(u_characters))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>31, Aug 1986\n"
     ]
    }
   ],
   "source": [
    "char2numX['<PAD>'] = len(char2numX)\n",
    "num2charX = dict(zip(char2numX.values(), char2numX.keys()))\n",
    "max_len = max([len(date) for date in x])\n",
    "\n",
    "x = [[char2numX['<PAD>']]*(max_len - len(date)) +[char2numX[x_] for x_ in date] for date in x]\n",
    "print(''.join([num2charX[x_] for x_ in x[4]]))\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>1986-08-31\n"
     ]
    }
   ],
   "source": [
    "char2numY['<GO>'] = len(char2numY)\n",
    "num2charY = dict(zip(char2numY.values(), char2numY.keys()))\n",
    "\n",
    "y = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in y]\n",
    "print(''.join([num2charY[y_] for y_ in y[4]]))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq_length = len(x[0])\n",
    "y_seq_length = len(y[0])- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "#     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    while start + batch_size <= len(x):\n",
    "        yield x[start:start+batch_size], y[start:start+batch_size]\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 128\n",
    "nodes = 32\n",
    "embed_size = 10\n",
    "bidirectional = False\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Tensor where we will feed the data into graph\n",
    "inputs = tf.placeholder(tf.int32, (None, x_seq_length), 'inputs')\n",
    "outputs = tf.placeholder(tf.int32, (None, None), 'output')\n",
    "targets = tf.placeholder(tf.int32, (None, None), 'targets')\n",
    "\n",
    "# Embedding layers\n",
    "input_embedding = tf.Variable(tf.random_uniform((len(char2numX), embed_size), -1.0, 1.0), name='enc_embedding')\n",
    "output_embedding = tf.Variable(tf.random_uniform((len(char2numY), embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "date_input_embed = tf.nn.embedding_lookup(input_embedding, inputs)\n",
    "date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)\n",
    "\n",
    "with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "\n",
    "    if not bidirectional:\n",
    "        \n",
    "        # Regular approach with LSTM units\n",
    "        lstm_enc = tf.contrib.rnn.LSTMCell(nodes)\n",
    "        _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=date_input_embed, dtype=tf.float32)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Using a bidirectional LSTM architecture instead\n",
    "        enc_fw_cell = tf.contrib.rnn.LSTMCell(nodes)\n",
    "        enc_bw_cell = tf.contrib.rnn.LSTMCell(nodes)\n",
    "\n",
    "        ((enc_fw_out, enc_bw_out) , (enc_fw_final, enc_bw_final)) = tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_fw_cell,\n",
    "                                                        cell_bw=enc_bw_cell, inputs=date_input_embed, dtype=tf.float32)\n",
    "        enc_fin_c = tf.concat((enc_fw_final.c , enc_bw_final.c),1)\n",
    "        enc_fin_h = tf.concat((enc_fw_final.h , enc_bw_final.h),1)\n",
    "        last_state = tf.contrib.rnn.LSTMStateTuple(c=enc_fin_c , h=enc_fin_h)\n",
    "    \n",
    "    \n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    \n",
    "    if not bidirectional:      \n",
    "        lstm_dec = tf.contrib.rnn.LSTMCell(nodes)    \n",
    "    else:\n",
    "        lstm_dec = tf.contrib.rnn.LSTMCell(2*nodes)\n",
    "    \n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)\n",
    "\n",
    "        \n",
    "\n",
    "logits = tf.layers.dense(dec_outputs, units=len(char2numY), use_bias=True) \n",
    "    \n",
    "    \n",
    "#connect outputs to \n",
    "with tf.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Loss:  1.340 Accuracy: 0.5484 Epoch duration:  8.784s\n",
      "Epoch   1 Loss:  0.805 Accuracy: 0.7039 Epoch duration:  8.627s\n",
      "Epoch   2 Loss:  0.661 Accuracy: 0.7539 Epoch duration:  8.569s\n",
      "Epoch   3 Loss:  0.566 Accuracy: 0.7937 Epoch duration:  8.572s\n",
      "Epoch   4 Loss:  0.510 Accuracy: 0.8195 Epoch duration:  8.580s\n",
      "Epoch   5 Loss:  0.431 Accuracy: 0.8484 Epoch duration:  8.592s\n",
      "Epoch   6 Loss:  0.367 Accuracy: 0.8797 Epoch duration:  8.663s\n",
      "Epoch   7 Loss:  0.334 Accuracy: 0.8734 Epoch duration:  8.707s\n",
      "Epoch   8 Loss:  0.294 Accuracy: 0.8938 Epoch duration:  8.704s\n",
      "Epoch   9 Loss:  0.261 Accuracy: 0.9203 Epoch duration:  8.617s\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 10\n",
    "for epoch_i in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "        _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "            feed_dict = {inputs: source_batch,\n",
    "             outputs: target_batch[:, :-1],\n",
    "             targets: target_batch[:, 1:]})\n",
    "    accuracy = np.mean(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "    print('Epoch {:3} Loss: {:>6.3f} Accuracy: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, \n",
    "                                                                      accuracy, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is:  0.888\n"
     ]
    }
   ],
   "source": [
    "source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "dec_input = np.zeros((len(source_batch), 1)) + char2numY['<GO>']\n",
    "for i in range(y_seq_length):\n",
    "    batch_logits = sess.run(logits,\n",
    "                feed_dict = {inputs: source_batch,\n",
    "                 outputs: dec_input})\n",
    "    prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "    dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "    \n",
    "print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Oct. 1970 => 1970-10-23\n",
      "22, Dec 1993 => 1993-12-22\n"
     ]
    }
   ],
   "source": [
    "num_preds = 2\n",
    "source_chars = [[num2charX[l] for l in sent if num2charX[l]!=\"<PAD>\"] for sent in source_batch[:num_preds]]\n",
    "dest_chars = [[num2charY[l] for l in sent] for sent in dec_input[:num_preds, 1:]]\n",
    "\n",
    "for date_in, date_out in zip(source_chars, dest_chars):\n",
    "    print(''.join(date_in)+' => '+''.join(date_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(dtype=tf.float32, shape=[None, 2], name='x')\n",
    "y_ = tf.placeholder(dtype=tf.float32, shape=[None, 2], name='y')\n",
    "\n",
    "W_ = tf.Variable(tf.random_uniform([2,2], -1, 1), name='W')\n",
    "b_ = tf.Variable(tf.zeros([2,]), name='b')\n",
    "\n",
    "logits_ = tf.add(tf.matmul(x_, W_), b_)\n",
    "\n",
    "unit_logits_ = tf.nn.l2_normalize(logits_, axis=1)\n",
    "unit_x_ = tf.nn.l2_normalize(x_, axis=1)\n",
    "unit_y_ =  tf.nn.l2_normalize(y_, axis=1)\n",
    "\n",
    "loss_ = tf.losses.cosine_distance(unit_logits_, unit_y_, axis=1, reduction=tf.losses.Reduction.MEAN)\n",
    "opt_ = tf.train.AdamOptimizer(1e-3).minimize(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random([100,2])\n",
    "y = np.matmul(x, np.array([[0,-1], [1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(a,b):\n",
    "    return 1-np.dot(a,b) / (np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist([0,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Loss:  0.938 Dist: 0.9377 Epoch duration:  0.008s\n",
      "Epoch  10 Loss:  0.181 Dist: 0.1809 Epoch duration:  0.007s\n",
      "Epoch  20 Loss:  0.138 Dist: 0.1381 Epoch duration:  0.007s\n",
      "Epoch  30 Loss:  0.040 Dist: 0.0400 Epoch duration:  0.007s\n",
      "Epoch  40 Loss:  0.049 Dist: 0.0495 Epoch duration:  0.007s\n",
      "Epoch  50 Loss:  0.027 Dist: 0.0265 Epoch duration:  0.007s\n",
      "Epoch  60 Loss:  0.017 Dist: 0.0172 Epoch duration:  0.007s\n",
      "Epoch  70 Loss:  0.016 Dist: 0.0156 Epoch duration:  0.007s\n",
      "Epoch  80 Loss:  0.016 Dist: 0.0157 Epoch duration:  0.007s\n",
      "Epoch  90 Loss:  0.005 Dist: 0.0052 Epoch duration:  0.007s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.3071613 , -0.54311997],\n",
       "        [ 0.68342453,  0.42378855]], dtype=float32),\n",
       " array([ 0.17894115, -0.2693293 ], dtype=float32)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "for epoch_i in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(batch_data(x, y, batch_size)):\n",
    "        _, batch_loss, batch_logits, W, b = sess.run([opt_, loss_, logits_, W_, b_],\n",
    "            feed_dict = {x_: source_batch, y_: target_batch})\n",
    "    dist = np.mean([cos_dist(batch_logits[i], target_batch[i]) for i in range(batch_size)])\n",
    "    if not epoch_i % 10:\n",
    "        print('Epoch {:3} Loss: {:>6.3f} Dist: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, \n",
    "                                                                      dist, time.time() - start_time))\n",
    "sess.run([W_, b_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12822016, -0.8124493 ],\n",
       "       [ 0.86236566,  0.15445924]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(logits_, feed_dict={x_:[[1,0], [0,1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70710677, 0.70710677],\n",
       "        [0.        , 1.        ]], dtype=float32),\n",
       " array([[0.70710677, 0.70710677],\n",
       "        [1.        , 0.        ]], dtype=float32),\n",
       " array([[5.9604645e-08],\n",
       "        [1.0000000e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.nn.l2_normalize(tf.constant([[1.0, 1.0], [0, 1.0]]), axis=1)\n",
    "b = tf.nn.l2_normalize(tf.constant([[1.0, 1.0], [1.0, 0]]), axis=1)\n",
    "cd = tf.losses.cosine_distance(a, b, axis=1, reduction=tf.losses.Reduction.NONE)\n",
    "sess.run([a,b,cd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.220446049250313e-16"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist([0.70710677, 0.70710677], [0.70710677, 0.70710677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist([0, 1], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
